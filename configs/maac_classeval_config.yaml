model:
  name: Qwen/Qwen2.5-Coder-7B
  type: qwen
  temperature: 0.6
  top_p: 0.6
  max_length: 2048
  tokenizer_kwargs: {}
  model_kwargs:
    trust_remote_code: true
    device_map: auto
    torch_dtype: bfloat16

dataset:
  name: FudanSELab/ClassEval
  type: classeval
  train_split: test[:66]
  eval_split: test[66:82]

output:
  base_dir: output
  save_final_model: false
  save_path: output/final_model
  verbose: false

external:
  mode: code_feedback
  original_prompt: true
  previous_response: true

maac:
  num_turns: 2
  critic_type: v
  num_train_epochs: 40
  per_device_train_batch_size: 1
  rollout_buffer_size: 2
  actor_learning_rate: 5e-6
  critic_learning_rate: 5e-6
  value_loss_coef: 0.6
  max_new_tokens: 600
  temperature: 0.6
  top_p: 0.6
  top_k: null
  num_agents: 2
  num_return_sequences: 1
  critic_model: null
  discount: 0.9
  early_termination_threshold: -0.2
  eval_interval: 10
  eval_num_samples: 4
  logging_steps: 1

reward_processor:
  enabled: true
  scale_factor: 1.0
  shift: -6.0

wandb:
  project: classeval_dev
  entity: null
  name: codecompletion_classeval_maac
  dir: output
  tags: ["maac", "classeval", "code-completion", "turns_2"]
